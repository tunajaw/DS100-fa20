{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 8: Multiple Linear Regression and Feature Engineering\n",
    "\n",
    "In this lab, we will work through the process of:\n",
    "1. Implementing a linear model \n",
    "1. Defining loss functions\n",
    "1. Feature engineering\n",
    "1. Minimizing loss functions using numeric libraries and analytical methods \n",
    "\n",
    "This lab will continue using the toy `tips` calculation dataset used in Labs 6 and 7.\n",
    "\n",
    "**This assignment should be completed and submitted by Monday October 26, 2020 at 11:59pm**\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others, please **include their names** at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John8\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "load-data-text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Loading the Tips Dataset\n",
    "\n",
    "To begin, let's load the tips dataset from the `seaborn` library.  This dataset contains records of tips, total bill, and information about the person who paid the bill. This is the same dataset used in Lab 6, so it should look familiar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "load-data-code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Records: 244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sns.load_dataset(\"tips\")\n",
    "\n",
    "print(\"Number of Records:\", len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John8\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1402: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  x[:, None]\n",
      "C:\\Users\\John8\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:276: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  x = x[:, np.newaxis]\n",
      "C:\\Users\\John8\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:278: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  y = y[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxcZ33v8c+ZTfu+WN73PIkTb1lIcJZLgeYGCgWSAqUh7C96L9BeCoSGhuU2QCkJ4dKG9UIhcIEGmq0lQFpIAoEkQBzHsZPYj/ddtrXvo9Es949zRlYmsqSRRnNmpO/79dJrrDNzZn5jSV89es6zOKlUChERyb+A3wWIiMxXCmAREZ8ogEVEfKIAFhHxyXwL4MPeh4iI70J+F5BnNclkqqajo7+gh37U1JQB0NMz5HMls2s+vM/58B5B73MyTU1VznjH51sLWESkYCiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCfzbTGeouE4EA4Hp3VuPJ5AO02JFD4FcAFywzdEbe30vjzd3YOMjCRyXJWI5JoCuIA9tv0YnT3RKT++vqaUyzctmcWKRCSXFMAFrLMnysmOAb/LEJFZootwIiI+UQCLiPhEASwi4hMFsIiITxTAIiI+UQCLiPhEASwi4hMFsIiIT3ydiGGMCQF9QGnGXQPW2krvMVcDnwXOB04BX7bW3p7XQkVEZoHfM+EMbvi+Hdgz5ngCwBizBXgA+BHwCeAK4DZjjGOt/UKeaxURySm/A3gjkATuttYOjnP/LcA2a+0N3ucPGmPCwM3GmDustcP5KlREJNf87gPeBOwfL3yNMaXAVcA9GXfdDdQCW2a/PBGR2VMILeBhY8yDuN0LI8CPgY8AS4EwYDPO2efdGuCRbF/QcaCmpmzaBedDMOiuAxyJhCgtDU/5vEjE/XJWVESKYj3gUMh9n4X+9ZiJ+fAeQe9zuvxuAW8EVgM/A14NfBp4C/AToMZ7TG/GOX3ebXU+ChQRmS1+t4DfDHRaa3d6nz9qjDkFfB+42jt2trZccjovmEpBT8/QdE7Nm9raMgKBELFYnGh0ZMrnxWJxAAYGYkWxIHu6FVHoX4+ZmA/vEfQ+J9PUVDXucV8D2Fr763EO/zTj88yWbvrzntxXJCKSP74FsDGmGfhT4GFr7YExd6U7V07hDkdbk3Fq+vPMvmERkaLiZx9wEvgG8IGM42/GDd5fAo8C1xpjnDH3X4fb+t2ajyLni/QmoNP9cJzJX0NEXsi3FrC1tt0Y8xXgr40xvcBvgMuBm3Fnu+0zxnwGN4jvMsbciTv07EbgprOMG5ZpCoWC1NaWT/t8bQQqkj2/L8J9GDgGvAu4CTgOfAq4FcBa+7Ax5jrg74H7vftv1FTk2aONQEXyx++LcCO4YXvrBI+5D7gvb0XNc9oIVCR//B4HLCIybymARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8ogAWEfGJAlhExCcKYBERnyiARUR8EvK7gLGMMfcCG6y1a8Ycuxr4LHA+cAr4srX2dp9KFBHJmYJpARtj3gq8IePYFuABYDdwLfAD4DZjzEfyX6GISG4VRAvYGLMI+GfgWMZdtwDbrLU3eJ8/aIwJAzcbY+6w1g7ns04RkVwqlBbwt4D/Ah5KHzDGlAJXAfdkPPZuoBbYkrfqRERmge8BbIx5D3AR8IGMu1YBYcBmHN+XPnWWSxMRmVW+dkEYY5YDXwTeaa1tN+YFmVrj3fZmnNbn3VZP5zUdB2pqyqZzat4Eg0EAIpEQpaXhKZ8XibhfzoqKCKlUdq/pOGeeI1+vGQq577PQvx4zMR/eI+h9TpdvLWBjjAN8G/iZtTazmwHAiwTO9mOdnJXCRETyxM8W8PuBDcB6Y0y6DgfA+7zHO5bZ0k1/3sM0pFLQ0zM0nVPzpra2jEAgRCwWJxodmfJ5sVgcgIGBGCMjiaxeMxwOUlub39dMtyIK/esxE/PhPYLe52SamqrGPe5nAP8Z0Ai0jnPfCPA/gQSwJuO+9OeZfcNzSiqV4mTHALsPd5FIpairLKG5roxQ0PduexHJET8D+C+BzF8LnwI24Y4HPgi8CbjWGPMla226K+I63Nbv1nwVmm99gzH+z79uZ/vethccLwkHWL+qgUWNFT5VJiK55FsAW2tf1II1xnQAw9bard7nnwF+CdxljLkTd+jZjcBN1trBPJabN32DMW7/zjMcOeVea6wuDxMOBejsG2Z4JMlW28aa/mHOW16Hk75yJiJFqSAmYpyNtfZhY8x1wN8D9wPHgRvn6lTkVCrFnT/fzZFTfYSCDldtXERFaQjHcRgcjvPMvnbauqPsO95LIpnigpX1CmGRIlZQAWytfcc4x+4D7st/Nfn32M6TPL23HYAPvHETg4MxTnYMAFBeEuLSdQvYsb+DI6f6OdjaR1lJiDWLayZ6ShEpYLqiUyCGRxLc8+v9AGxZv5CXX7z0RY8JOA4bVzewqLEcgOcPdXGifSCvdYpI7iiAC8Qj247TMxAjFHR4x5+cd9auBcdx2Ly2kfrqEgC27Wmjq09LYogUIwVwARiJJ3nw94cBeNmmxTTWTjzLJhgI8JJzm6koDZFMwZO7TxP1xuOKSPFQABeAp/acpndwhIDj8KrLlk/pnEg4yEvOayYUdIjGEmzd3UYiqcmBIsVEAVwAfv30CQA2r22krqpkyudVlUe4cG0TAJ19wzy+8+Ss1Ccis0MB7LPWjgHs0W4A/tvmRVmf39JQzjlL3ZEQuw538Z+/O5zT+kRk9iiAffb7508B0FBdwroV9dN6DrO0lpZ6t9/46/fu4LmDnTmrT0RmjwLYZ1utO934knMXEJjmpAp3ZEQTtZUlxBNJvvTj7Rw6mbmKp4gUGgWwj4639Y+O473kvOYZPVc4FODVL11OY20Z0ViCL/7oGVo7NEZYpJApgH2Ubv021pSyomX85eqyUVkW5pb3vpTKsjD9QyN8/odPc7BVLWGRQqUA9tGO/e604wvPacrZmg5LF1Rx419sprwkRO9AjM//cBvbvenNIlJYFMA+6R2McajVXfFs/eqGnD73qkU1/N0NF9FYU0psJMkd9+7g3kcPEE9onLBIIVEA++S5A52kgEg4wDlLanP+/IsaK7j5bRezcmE1qRQ88PghPvPdrRw73Z/z1xKR6VEA+2TngQ4AzltWRzg0O1+GmooIN11/Ia+6bBmOA0dO9/P3dz7J3b/az3CW2weJSO4pgH2QTKV47pA7VveCVbntfsgUDgV448vW8LHrL2JBXRmJZIqf/e4wH//m79U3LOIzBbAPTrQP0Dfobny5bkVdXl5zzZIabnn3S3jdFSsJBR06eqP88z07+Op9O+kfmvomnCKSOwpgH9gj7tTjmooILfXleXvdcCjI665YyS3vvnQ0+LfaNj717T9wSMPVRPJOAeyD3Ue6ADjXp33dWurL+fCbN/HOV59LSThIV98wn/7uk2zddSrvtYjMZwrgPEumUqMtYLMs96MfpspxHK7csIiPv+3McLV/uPMPHNUoCZG8UQDn2Yn2gdE+13OX5af/dyKLmyq5+YaLWNRQwUg8yS+ePErPQMzvskTmBQVwnu073gO4280vqJt454t8qaks4WM3XERTXRnxRJI/PH+KmIapicw6BXCe7T/mBvDqxTUFtaV8bVUJn3jXpYSCAYZiCZ7Z30EqlfK7LJE5TQGcZ+kW8Jolhbed/MpFNWxZ3wJAa8cgx7XjssisUgDnUd9gjFNdQwCsWVx4AQwvXNz9uYOdjMTVFSEyWxTAebT/uDvWNhhwcrL85GxwHIf1qxoIBhyGR5Ls9kZsiEjuKYDzaP8Jt/theUsV4VDQ52rOrqwkxDlL3SFyh072MRDVTDmR2aAAzqNDJ93lJ1e2VPtcyeRWLaqiNBIklYI9R9UKFpkNCuA8SaVSHPYCeHmBdj+MFQwEMF4r+OjpAa0XITILFMB50tEbHQ2xQu3/zbS0uZLykhAA+73RGyKSOwrgPEm3fiOhAAsb87cAz0wEAg6rF7vdJUdP9xONxX2uSGRuUQDnSbr/d+mCSoKB4vlvX9pcSSQUIJlidAslEcmN4kmCIpcO4BULCv8C3FihYGC0z/rwqT6SSc2OE8kVBXAeFNsFuEzpmodHkrR2aHacSK4ogPOgGC/AjVVeEhpdOP7QSS1XKZIrCuA8KMYLcJmWL6gE3F8mg1FdjBPJhawC2BjzsDHmFRPc/1pjzHMzL2tuGb0A11xcF+DGaqorIxJ2az/WplawSC6EJrrTGFMONI459DLgPmPM3nEeHgBeBazMWXVzxKEi7v9NCzgOS5oqOXCil6On+1m7pLCW0xQpRhMGMFABbAfSS3elgC95H+NxgF/kprS5YewFuBVFMAV5Ikub3QAeiMbp7o9RV1Xid0kiRW3CALbWthljrgdeghuunwTuA3aM8/AE0Abclesii1ln7/DoBbhibgGDu4tzdXmY3sERjp7uVwCLzNBkLWCstT8Hfg5gjFkOfN1a+/tcvLgxxgH+F/A+YCmwB/i8tfaHYx5zNfBZ4HzgFPBla+3tuXj9fDjq9ZeGgg4LG4rzAtxYS5oref5QF8fbBzh/Zb3f5YgUtayuCFlr35mr8PV8DPgC8F3gNbjdFz8wxrwJwBizBXgA2A1cC/wAuM0Y85Ec1jCrjnm7DC9sqCAULM4LcGMtaaoAYCSe5LS3uLyITM+kLeBMxphrgOuBFmC8RW1T1tqzjpQY8zxh4CPA16y1n/UOP2SMuRj4K+DHwC3ANmvtDd79D3rn3WyMucNaO5xt/fmWHjGwpKnS50pyozQSorGmlPaeKK0dA2ymye+SRIpWVgFsjHkfcIf36SlgJgGYAP4b0JFxPAbUGWNKgauAmzPuvxv4KLAFeGQGr58Xx9rcmWNLm+dGAAMsaiinvSfKyc5BEsmk3+WIFK1sW8AfBJ4BXmWtPTWTF7bWJoGdMNoX3Ay8E3gl8JfAKiAM2IxT93m3hgIP4JF4gpMdgwAsaa7wuZrcaWkoZ8eBTuKJFMfbNDVZZLqyDeClwAdnGr7juBa3ZQvwU+D7wCbv896Mx6aX5JrWmC7HgZqasumcmrUDJ3pIelu7r1vdSE1V6ZTOCwbdnp1IJERpaXjKrxeJuF/OiooI2e4onx7SO5XXLC0N01hbSnt3lCOn+qf9miFvW6Z8fT38MB/eI+h9Tle2V4X2Awty8sovtA23O+KvgMtxQzg9yv9sP9YF/7fvYW/5xuqKCLWVc2vIVrpP+8CJHhKJgv9SiBSkbFvAnwP+yRhzj7U2Z1OOrbUHgYPAo8aYXtxREekAzmzppj+f1hYNqRT09OTn6v2ew50ALG6soLc3OuXzamvLCARCxGJxollsiBnzFkwfGIgxMpLddvLhcJDa2qm/ZlON25qPxhI8u7+D5c0VWb9muhWRr6+HH+bDewS9z8k0NY0/ByDbAL4C6AeeMcZY3IkXmc2fqY6CqAf+BHjIWntizF3bvNuVuBfq1mScmv48s2+44My1ERBjlZWEqKuM0NUf47GdJ1j+irV+lyRSdLLtgrgGt0vgKFAOLMcNyrEfq7J47e/iXnAb62rv9kngUeBa7yJd2nW4rd+tWdaed+kxwHPpAtxYCxvc9/W7na2jfd0iMnVZtYCttTlbaMda226M+SpwkzFmEDdQr8CdnPEta601xnwG+CVwlzHmTtyhZzcCN1lrB3NVy2zoGYjRO+j+KT+XhqCN1dJQzvOHu+jqG+ZQay9L52BLX2Q2+T0162+ATwDvwr3wdgPwKbxWsbX2YdwW73nA/bgTQG601t7qS7VZSLd+HQcWNczNFnBlWZiaiggA2/e2+1yNSPHJdiLGw1N5nLX25VN83Ahwq/dxtsfch7sAUFE56gVwS305kfB4EwbnhmULqth5oIPte9t47ZYVfpcjUlSyvQi3ihcPCwvirhlcChwCnp15WcXv+By+ADfW8hY3gA+29tHVN6wV0kSykG0f8IrxjhtjgsDrgG/hLq4z76WnIC9umpvdD2kt9eVUlIYYiMbZeaCDqzYu8rskkaKRkz5ga23CWnsv8E3g87l4zmKWTKVGdw9e3lJNOBzM6mN0o4ki2HAiEHC48Fx3bs4z+9QPLJKNrFdDm8Re3Nls81p7T5RY3B0efe6qBmprp7cOcKBItvy5ZN0CfrP9OM8d6mQkniAcmrt93iK5lLMANsaUAG8FTufqOYvVCa/7IRQMcPBYN0/vym7pjNXLalm3snHyBxaIC00zjgOxkSS7j3SzflWD3yWJFIVcjYIowV2drA53GNm8drw9PQGjku6+YU52ZLdiWHORDVurqSxh7ZJa9hzt5pl97QpgkSnKtg94FS+e+bYSd4Ge3cBf424fNK+daHfniCxbUNx7wGVj01q3xf7Mvg5SmhUnMiU5GQUhL3Si3W3xLivyTTizsWltEz9+eB8dvVGOtw/M+eF3IrkwrT5gb9jZxbhrQcSAI9babROfNT+MHQGxrKWK9s6CnjGdM0uaKmioLqWjN8oz+9oVwCJTkPUwNGPMa3CXjnwcdwv6e4EnjTFHjTGvzXF9Rae9e2h0BMSylmmtGV+UHMdh4xq37/eZfZm7TInIeLIKYGPMlbiB6wB/B7wedzeLm3FnyN3j7WQ8b6X7f0NBh5b64t+GPhsbVrv9wPtP9NA/NPV1jEXmq2y7IP437nTjS6y1L1gQ3VvZ7Eng48Crc1FcMUqPgFjYUEFwDmxDn41zl9USCQWIxZM8e7CDy9a1+F2SSEHLNiFeAnwzM3wBrLW9wL8Al+WisGKVvgA3H/tAI+Eg5y6vA2DnfnVDiEwm1020FO5OxvNWugti0RxfA+JsNqx2+4F3HugkmdRwNJGJZBvAvwfebYx5UboYY6qA9+B2Q8xLY0dAzMcWMMAGbxJG/9AIB1szN7QWkbGy7QP+e+AR4FljzJeBPd7xc4H3AUuA/5G78orL2BEQc30VtLNprC1jUWMFJ9oH2LG/g9WLa/wuSaRgZdUCttb+BnfUQwi4DXeXin/HXQEtArzZWvtIrossFmdGQARorivzuRr/pFvBOw6oH1hkIln3AVtr/wNYAVwKvMX7uBJY7i1JOW+lR0C01JcTDMyvERBjrff6gQ+f7KO7f9jnakQK15S6IIwxH8Ddp22ztTZurU3g9vU+aYz5IfAK4B+B/zNrlRaB9AgIv7ofQt6wt+kMfxs9JwcrYK5dUkNpJEg0lmDngQ6u3KBF2kXGM2EAe9vBfxd3mcku3KnH+zMedgD4I+ALxpiXWGvfMhuFFoPjXgAvavQngKsr3Q0yq6pKp/0cuViDOBQMcP7Kep6ybezcrwAWOZvJWsDvwQ3frwIfsdZGMx9grf24t33814EbjDE/t9Z+L/elFrZkMkVrhzcEzeflJJ/YcYL2ruzWoFixqJr1a5tzVsOGVQ08Zdt47lAn8URytHUuImdMJYAftdZ+YKIHWWujxph3ARtwuyrmXQC39wwxUiAjIDp7hrJeg7i+Zvqt5vGk+4GHhhPsO9YzOkFDRM6YrFlyPu4oh0lZa5PA3bghPO+kux9CwQDNtfN3BERabWUJy731kDUaQmR8kwVwHHhRt8ME2oHk9MspXukLcAsbygkEimMvt9mWbgVrWrLI+CYL4L246/5O1SXAkemXU7xO+HwBrhClpyUfbx+gvWfI52pECs9kAXwXcL0x5vzJnsh7zPXAz3JRWLHxewREIVq1sJrKMndpELWCRV5ssgD+BnAY+JUx5npvJ4wXMMYEjDFvAX4B9AFfyn2ZhW3sCIjFCuBRgYDDBavqAdihABZ5kQlHQVhr+40xf4p7Ie57wFeNMU8BrUAQaAYuAipxux7eYK1tnd2SC8/YERBqAb/QhlUN/O65U+w63MVIPEE49KLf4SLz1qSDM621FtgI3AhY4Arc6cdvArYA24APAudaa7fPXqmFSyMgzu6CVQ04QCyeZPeRbr/LESkoU5qKbK0dBr7ofWCMaQQS1tquWaytaGgExNlVloVZtbia/cd72bG/g/XeQj0iMs0F2a217QrfM0bXgFD3w7jSe8Xt2N9OKqVF2kXSND80B9JdEAsVwONKL0/Z1h3lVJeGo4mkKYBnKJlMcVIjICa0bEElNd5CQTv2tftcjUjhUADPUFvPmF0wFMDjchxntO9X05JFzlAAz9CJNrf7IRwK0KQREGe10ZsVZ490E43Ffa5GpDAogGdotP+3XiMgJrJuRT3BgEMimWLXIV2/FQEF8IyNrgExTzfhnKqykhBrl7gbdD6jWXEigAJ4xo61aQjaVKWHo+080KHhaCIogGckkUxysjMdwJU+V1P40qujdfUNj/7ichwIh4PT+sjB7kkivprSTLjZYowJAO8F3gesAk7hrjvxKWttn/eYi4Ev4C6L2Qvc6d0/4kfNY53uGiKecFty6oKY3MKGchprSmnvibJjfzvrz2kiHA5RWzu9b8Pu7kFGRhI5rlIkf3wNYOCjwGeA24CHgHOATwPrgGuMMWu844/jrj1xHvBZoBqYcJukfEj3/0bCARpzvKXPXOQ4DutXN/DItuPs2N/B9d7xx7Yfo7Nn6uv+19eUcvmmJbNTpEge+RbA3o7LHwW+Ya39mHf4l8aYDuAuY8wm3JDtAV5nrY0BPzPGDAJ3GGM+Z6097kvxntEREA0VOdlNeD7YsMoN4H3He+jpH6axLkRnTzTrPexE5gI/+4CrgO8DP8w4vtu7XQ1cDfzEC9+0u3GXwrx61iuchNaAyN66FXWURIKkUrB112m/yxHxlW8tYGttL/DX49z1eu92F7AUdwnMsee1GWN6ATOd13UcqKnJzYSJk53uugarl9a+6DnTDeJIJERpaTi7Gr1fi6FQMKtzQ95au9meN5NzIxH3W6iiIsJUBzZcaJp5Ymcrf3j+FNdsWZn1/9F0XtMv6f/XXH3PFSq9z+kpqFEQxphLgZuA+4H0aP3ecR7ah9sP7Jt4IsmJ9n4AljZX+VlK0bl03QIAtu9tYzDq+7VUEd/4fRFulDHmcuAB4CDwHqDEu2u8No7DNHdfTqWgJwcbRB5vHxgdAVFbHnrRc4bDQWprQ8RicaJZhkzKe2fxeCKrc+PxxLTOm8m5MW9a8cBAbMojEtYsrCYYcBiJJ9lmT2f9fzSd1/RLuqWUi++5Qqb3ObGmpvEbaQXRAjbGvBn4Je62Rq+w1nZwpuU7Xku3EvfinG/S/b8lkSAN1RoBkY3y0hDrVrh7xT2xc97tYCUyyvcANsZ8CPhX4AngqvSectbafuA4sCbj8c24oWzx0fE2t/thUUMFjkZAZO3Cc9xZcVt3nSKRnNYfMyJFz9cANsa8G7gd+DFwjbU2s1X7X8BrjTGRMceuAxLAr/JS5FloBMTMbFrbhOPAYDQ++n8pMt/4OQ64Gfhn3G3vvwxcaMwLBjbsA27F3QD0Z8aYL+FO1PgH4P9aa4/kt+IXSo8Bnu+7IIeC7u/wYDC73+WNtWWcu7yOXYe6ONjaxzneQj0i84mfF+GuAcqB5cBvxrn/Bmvt940xV+POlLsbaMfdGPRTeatyHPFEktPe1jpL5vkU5Gpvp4uqquz7wbdsWMSuQ10cPtnL2sXV6sqRecfPccDfA743hcf9Brhs9iuaupOdgySS3hoQ87wFnPbEjhO0dw1mdU5jrRvaQ8MJOvuGdTFT5p2CGYZWTI57K3mVlQSpqyqZ5NHzQ2fPUNbTiZsbKli1qIYDJ3po7RhUAMu84/soiGI0tv9XfzbPzGXrFwJwsmNQawTLvKMAngaNgMidyze4ATw4HKerf9jnakTySwE8DWdawFqEfaaWtVSPdj2ku3ZE5gsFcJaGRxKc7nQvNi2d5yMgcmWNNwTtRLu6IWR+UQBn6UT7wOjiFIub1QLOhdWL3QAeHknQnsXC7CLFTgGcpaOn3SnINZURqssjkzxapqK6IjI6muS4ZsXJPKIAnkTmppEnvKFWy5qrJtwwcnRmmAZJTEn6gmZrxyDJpLohZH7QOOBJhEJBamvLRz9v7XBnwK1ZVveC42ejrYqmZlFjOc8e7GQknuR09xAt9ZP/34oUOwXwFD22/Rgd3UPsOeKuE9/VM8RPfr3vrI9fsaia9Wub81Ve0SuNhEZ3TD56ul8BLPOCAniKOnuiHGrtZdhbADyVSk0486teuyRnbVlzJe09UU52DjI8kqAkHPS7JJFZpT7gLPQOunuDOg5UlmW355pMbmFDOaGgQyoFx7yLnSJzmVrAWegdcLfNqSwLEwyobzfXgsEAS5oqOXSyjyOn+1m1KLcrpDnOmU0VpyseTxT8RqBSPBTAWegdcFvAGn42e5Y1uwHcNzhCd38sp4sdZV5QnY7u7sGC34dOiocCOAvpLojqCgXwbKmpjFBVHqZvcIQjp/tnZbW5x7YfozPLCR/1NaVcvmlJzmuR+U0BPEWJRJL+IbcLorpC/b+zxXEcli2o5LmDXRxv6+f8FXWju27kSmdPNOulM0Vmgy7CTVF3f2y0709dELNrSVMlAQfiidTozEORuUgBPEUdve6frOFQgNKIhkfNppJwkCVN7jobB1t7tUCPzFkK4Cnq8PoMq8sjWoQ9D1YtqgagfyjO6e4hn6sRmR0K4ClKt4BrKtX9kA/VFREavcksB070+lyNyOxQAE9BKpWi3WuF1WgERN6kW8Ft3dHRESgic4kCeApOdQ4SiycBqFULOG8W1JVRUeoO1DlwXK1gmXsUwFOw/3gPAMGAoynIeeQ4zmgr+Ojp/tFhgCJzhQJ4CvYf6wbcfkldgMuvZQuqKCsJkgL2HO32uxyRnFIAT0G6Baz+3/wLBhzM0loAjrUN0Ke+YJlDFMCTSKVSHDjmBbD6f32xpLlytC949xG1gmXuUABPort/mO7+YQBq1TI8kR0AABSUSURBVAL2RcBxMMvcVnBrxyCnuzQuWOYGBfAkDrX2AW4IVGkKsm8WN1ZQXe5eAH1sZ6v2jZM5QQE8icMn3QCury4hoDWAfeM4DutXNQDQ1j3Ef/3+sM8VicycAngSh066408btMWQ7xpqSlnS5O6e/O2fPEd7j7oipLgpgCdxyGsBN9aU+VyJAFywsp6ykhBDw3G++R/PqytCipoCeAKJZJJObw2Iplq1gAtBJBzkyo0LAXj+UCcPPH7I34JEZkABPIFgIMAb/2gNb3zFWppq1QIuFCtaqnnNFSsB+PffHmT73nafKxKZHgXwJF57+Ure9up1mgFXYN712vNZvbiGFPCN/3iOg61aK0KKjwJYilI4FOSDb9pIQ3UJwyMJvnDXdi1bKUVHASxFq7ayhA+9eRM1lRGGhuPc/qOn2edNGxcpBgpgKWoLGyq46S8upK6qhKHhBLfftZ2nbJvfZYlMiQJYit6C+nL+9i8201BdyvBIgq/ct5N//+1BktpLTgqcAljmhOa6cj7x9otZu6QGcEdHfOXenQxG4z5XJnJ2BRPAxphNxpgRY8ySjONXG2OeNMYMGmMOGmM+7FeNUtiqKyLc+JbNvGzTIgCe3tvOLd99UlvbS8EqiAA2xhjgASCUcXyLd3w3cC3wA+A2Y8xH8l6kFIVQMMDbrjmXd7zqXELBAKe7hvjs97byxLMn/S5N5EVCkz9k9hhjQsB7gX8Exttv5hZgm7X2Bu/zB40xYeBmY8wd1trhPJUqReaqjYtYtqCSr973LO09Ub75wPMcaO3l/W/a5HdpIqP8bgFfAdwK3A787dg7jDGlwFXAPRnn3A3UAlvyUaAUrxUt1XzyHZeMrqL20FPHuPlrjxONqV9YCoOvLWBgF7DKWnvaGPOOjPtWAWHAZhzf590a4JFsX9BxoCaLhXXSE+AikRClpVPfkDMUCo7eZnMegBM48xz5es3pnuvH+4xE3G/biooIkw10qKkp45PvvpS7H9nHjx/aw65DnZzqHOTyDQspK5n6t382rzlW+v8nm++5YqT3OT2+toCttaestafPcneNd5s5vanPu62enapkrgkEHN70irX8zZ9vJhR06OyN8vDWo9plWXzndwt4IunFF87W3khO50lTKejJYh3ZcDhIbW2IWCxONDr1H9h4PDF6m815AKnkmefI12tO91w/3mfM60IYGIgxMpKY8nmb1zTyiXddxqe//TsGonF+te0YV6xvoTQy+Y/BdF8z3VLK5nuuGOl9TqypqWrc4373AU8kPac0s6VbnXG/yJRdeG4zr75sOcGAw2A0zu+eP81IfFq/y0VmrJADeD+QANZkHE9/ntk3LDIlLQ0VXGyacIDegRh/2HVaC7uLLwo2gK21UeBR4FpjzNi1IK/Dbf1u9aUwmRMW1JezaW0jAB29UZ492OlzRTIfFXIfMMBngF8Cdxlj7sQdenYjcJO1dtDPwqT4LW2uZCA6wp6jPRw62UddVQlLmyv9LkvmkYJtAQNYax/GbfGeB9wPXA/caK291dfCZM4wS2tprnMvrDyzv4Oefs3tkfwpmBawtfZO4M5xjt8H3JfvemR+cByHC89p5NFnWhmMxnnStvGyjYsIhQq6bSJzhL7LZN6LhIJccm4zAQcGo3F2qj9Y8kQBLALUVERYt6IegKOn+znRPuBzRTIfKIBFPCsXVtFUWwrAM/s6GBrWmhEyuxTAIh7Hcdi8tpFIKMBIIsnTe9tJaVcNmUUKYJExSiMhNq5xxwe390Q5dLJvkjNEpk8BLJJhYUP56Hjg5w910T+oRXtkdiiARcZxwcp6ykqCJJIptu1t01RlmRUKYJFxhEMBNntdEd39Mbbva/e5IpmLFMAiZ9FYW8aqhe7ie0/Z0+w71u1zRTLXKIBFJnDe8loqy8KkUvDFH24jFp/6WsAik1EAi0wgGAxw4dpGHAeOnurj7kf2+12SzCEKYJFJ1FaVcOE5TQA8+LvD2CNdPlckc4UCWGQKNq9tYs3SWlLAv/x0l2bJSU4ogEWmIBBw+NBbLiQcCtDeE+Wuh/b6XZLMAQpgkSlauqCKN79iLQC/2dHK758/5XNFUuwUwCJZ+ONLlnL+SnfVtO/8fBfH2vp9rkiKmQJYJAsBx+G9r11HQ3UJsZEkX7l3J4NR9QfL9CiARbJUVR7hfW9YTygY4FTXEP/3J8+RSGpre8meAlhkGlYurOaGq88BYMf+Dr73oNXSlZI1BbDINF25cRF/8tLlgHtR7v7fHPS5Iik2CmCRGbj2qlVcvr4FgJ88foifPnHI13qkuCiARWbAcRzefs25bFzdAMA9vz7Av/1qn7ojZEoUwCIzFAoGeN8b1nORcacr//x3R/jug7sZievCnEws5HcBItkKBd12QzCYXfth9PFO7l8zHA7yV3+2gW8/sItHnznBo8+0cqxtgI/ecBHNdeU4DmTbKHYcCIWC2RfriccTWb+m5JcCWIpOdWUEgKqq0mmdH3CyT+CpvuaH33oxixdY7vqF5cCJXm6847f8z2s3csGKWuJZtohDoSC1teVZ15rW3T3IyIiWzyxkCmApWk/sOEF71+CUH79iUTXr1zbP+mtWlYZ41aXLeXjbMfoGR7j1+1u5YFU9f/HKc2ipzz5QH9t+jM6e6JQfX19TyuWblmT9OpJ/CmApWp09Q5zsGJjy4+trptdins5rhoIOV25YyN7jvRxq7eXZA5184lu/56UXtPAnly1nQRZB3NkTzep9SvFQAIvMkrKSEK+5fCW1VSV8/d4dtPdE+e2OVh7b2crmtU1cuWEhF6yqJxjQtfD5SgEsMssuvWAhq1qq+NW2Y/zsd4dp74mybU8b2/a0UVsZ4SLTzIXnNHHO0hqF8TyjABbJg3AowMs2L+aKDQvZak/zm2da2XW4i+7+GA89dYyHnjpGZVmYjWsa2Ly2ifNX1BMOT38EhBQHBbBIHoWCAS5b18Jl61o43T3EH54/xbY9bRw62Uf/0AiP7TzJYztPEgoGuGBVPVs2LmYgOuJ32TJLFMAiPmmuLeM1W1bwmi0r6OiJsm1vG9v3trPnaDfxRJLte9vZvrcdgNrKCAvqymlpKKe6PIwzjaF0UngUwCIFoKGmlD++eCl/fPFSBqMj7DzQyY79Hew40MHA0Ajd/TG6+2PYo91UlYdZ0lTJkqYKykr0I1zM9NUTKTDlpWEuXbeAKzYuorKqlH+5fyfPH+zkZOcgg8Nx+gZH2HW4i12Hu2ioLmVJcwWLGioIh3QBr9gogEUKWCgYYFFjBQEHzl9ZR3d/jGNt/RxvHyA2kqSjN0pHb5SdBzpZWF/O0uZKmqcx2UP8oQAWKRKO41BXVUJdVQnnr6inrWeIY6cHONk5SCKZ4nj7AMfbB9hxoIOu/hiXmCaaa8v8LlsmoAAWKUKBgMOCunIW1JUzEk/S2jHAkdP9dPYOMxiNc88j+7jnkX2saKliywUtXHhOE/XVM58JKLmlABYpcuFQgGULqli2oIqB6AhdfTGOtw9wqnOQQyf7OHSyjx/+ci8rF1axeW0Tm9Y0sripQiMpCoACWGQWhYJuyGW7dOYLzskiJytKw6xeXMunrlzNH3ae4Nfbj/P0njYGonEOtvZxsLWPex89QFV5GLO0FrOsjrVLaljUWEEoGJj2EpjpLJ/OspvTNZPlOoPBAIlE9us15/p9FkUAG2PeAnwcWAUcAj5nrf2er0WJTEFl+cyWzoTpLZ8ZCDicu7yO1YuqSVxj2HO0h6f3tPH03jY6eofpGxxhq21jq20D3It9S5srWbmoGrOiniXNlSxprqKuqiSrlnIoFMzbEpgzXa5zpq+di/dZ8AFsjHkj8APgn4AHgdcD3zXGDFpr7/a1OJEpynbpTMjN8pkAwUCA85bXcd7yOt7yyrWc6hpi9+Eudh/pwh7ppmcgRjyR5GBrLwdbe3n4qWOj54ZDAWorS6ipiFBVHqaqPEJleZiqsjCVZeHRVvqCxgpecv7CGdd6NqlUipF4ksHhOIPROIPDcWLxJJGSEM8f6KBvIEbKfSCpFEzUOG2sLWNpSxX7jnbTNxA76+MCjnvh0xlz21xfznUvPydn76vgAxj4HPBja+3feJ//pzGmHvg0oACWopDt0pmQm+UzMzmOQ0t9OS315bxs82JSqRRdfcMc9vqKj7b109oxyKlO95fFSDxJW/cQbd1D4z5fSThIaSRIbVUJj+9spTQUpLIsRHlJiJJIkJKw+xEInGlFp1IpYvEk0ViCaCzOcCxBNJZgKOaFqxew6duh6AiDw3HiicLY3qO9Z5jrX7k2J89V0AFsjFkFrAY+lnHX3cCbjDErrbXaC1xkmhzHob66lPrqUjaf00Q47P5Zf9/DezhwvIf+oRH6BkcYHB45E4jDZ/70Hh5JMDySoGcgxuGTfXmtPRR0KImEiMeTpFIpr3/WOdNPe5bzwqEAkUiI6HD8rP3AKfBa0l6L2mtZh4IBzllam7P34BTy7q3GmFcDPwU2Wmt3jDm+GdgGvMpa+2AWT5lMpVJZd6g5jkM8kcyq0z3guB392Z4HEAi4fzbm9TWneW4xvU9f/n+m+R5n8pqO4wbFdH+2J/9+H/Nnfirl3QLehan066bPH+9p0j+EZy5qOaOfO94/nNH7nbMcz//P5nT/bx3HOQIszzxe0C1goMa77c04nv5VW53l8yUdxwmM83yTCk3jKvZMztNrFt55xfaaMxlmNpN6882Pr0muhvAVegCn32Xmr5v08WzHkRT6+xWReaTQf831eLeZLd2qjPtFRIpOoQew9W7XZBxfk3G/iEjRKegAttbuAw4Cf5Zx13XAXmvtkfxXJSKSG8XQJ3oL8B1jTBfwAPCnwJuAP/e1KhGRGSroYWhpxpi/BD4CLAUO4E5F/n/+ViUiMjNFEcAiInNRQfcBi4jMZQpgERGfKIBFRHyiABYR8YkCWETEJwpgERGfFMNEjHnDGBMA3gu8D3f7pVPAvwOfstbmd7HVPDHG3AtssNZmTjcvesaYq4B/AC4EuoF7gI9Za/t9LSzHjDH/A/hfwDJgP/B5a+0P/K0qN4wxm4AngZXW2mNjjl8NfBY4H/fn9MvW2tuzfX61gAvLR4Ev466B/HrgduDtwL/5WdRsMca8FXiD33XMBmPMZcAvgJO4szdvAd4KfMvPunLNGPNe4Gu437OvA34JfN/bSqyoGWMM7uzbUMbxLd7x3cC1uFum3WaM+Ui2r6GJGAXCGOMAHcC/WmvfP+b4m4G7gM3W2u1+1ZdrxphFwLPAADA811rAxphfe/98mbU25R17P/AhYL21NrsN4gqUMeZxIGqtffmYY48CCWvtH/lX2fQZY0K4f4n+IzAC1ANL0y1gY8wvgUpr7WVjzvm8d06LtXZ4qq+lFnDhqAK+D/ww4/hu73Z1fsuZdd8C/gt4yO9Ccs0Y0whcCXwtHb4A1tqvWGtXz5Xw9ZRyZoOEtA6gwYdacuUK4Fbcv0D/duwdxphS4Crc7qSx7gZqgS3ZvJD6gAuEtbYX+Otx7nq9d/tcHsuZVcaY9wAX4faffcHncmbDetxNAzqNMT8CXgPEcX+5fshaO/4Ol8Xpn4Bvel0O/wlcjft+/87XqmZmF7DKWnvaGPOOjPtWAWFevBTuPu/WAI9M9YUUwAXMGHMpcBNwv7V292SPLwbGmOXAF4F3Wmvb3W62OafJu70TuA94LbAR+AxQBrzDl6pmx78CLwd+PObYd621t/lUz4xZa09NcHdOt0lTABcoY8zluB39B4H3+FxOTnj93N8GfmatzfwTbi6JeLePj+nPf9h7/18wxtxirT3gU2259h+4f3Z/CHej3EuBTxpjeq214/1FV+zOtk1aWlbbpCmAC5B34e1OYA9wjbW2w9+Kcub9wAZgvXehA7xvaO/zxNg+0yKWbg39LOP4f+L2K67HXVa1qHmjAf477l8zd3qHf22M6Qa+YYz5prV2p28Fzo6zbZNWnXH/lOgiXIExxnwI98+6J4CrrLWtPpeUS38GNAKtuFeXR4C34V5gHMEdcjcX7PVuSzKOp1vGc+GXDJzZZv2xjOOPerfr8lhLvuwHEuRomzQFcAExxrwbt4X0Y9yW71zbdPQvgUsyPh4Ajnn//ol/peXULuAwL961JX0x7om8VzQ70mFzVcbxl3q3h/JXSn5Ya6O4v2Cu9bqU0q7Dbf1uzeb5NA64QBhjmnH7e9twB+zHMx6yz1rbnvfCZpkx5k7gijk4DvjNuH/J/BC3O+ki3MkYX7bWftjH0nLKGHMf8Ergk8DTwMXev39rrX21n7XlgjcK4ju8cBzwy3EnnPwb7td2C3AzcJO19tZsnl8t4MJxDVCO+2fdb3BbSWM/rvGvNMmWtfZHuLOk1uG28t+PG8A3+lnXLPhz4A7gb4AHcS8Yf4E5OsMRwFr7MG6L9zzgfuB64MZswxfUAhYR8Y1awCIiPlEAi4j4RAEsIuITBbCIiE8UwCIiPlEAi4j4RAEsMoYxptkYU+H9+05jjMZpyqxRAIt4jDGvwp1em15O8hvADf5VJHOdVkMTOeNS3F0NALDWpmchiswKtYBFRHyiqcgijC4KNHY5zF/jrub1dmutM+YxV+B2S9yBu6XSYeBL1tqv57FcmSPUAhZxfQN3+yBwF5b57Fke14C76Mxe3IV1TgBfM8Z8bNYrlDlHASzCaH/vDu/T+621vzjLQ2uB71hr32Kt/TLwx7jrw37CGFOXh1JlDlEAi2Tvc+l/WGsTuDsDl+GuiysyZQpgkex0jrNrbnoLohV5rkWKnAJYJDuxcY4FvdtEPguR4qcAFsnOAmNMZcaxtd7t3swHi0xEASxyRroFO9HPhYO7vRAAxpgQ8EHcDRkfmr3SZC7STDiRM9q82xuNMT+f4HGfNMasAJ4D3oS7KeO7rbWDs1yfzDFqAYuccRfubrfvBD4/weOuxp2QcRtQAVxrrf327Jcnc41mwolMUXq2XHpmnMhMqQUsIuITBbCIiE8UwCIiPlEfsIiIT9QCFhHxiQJYRMQnCmAREZ8ogEVEfKIAFhHxyf8H9MYAu3VB30QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(x=data['tip'], kde=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 1: Defining the Model and Feature Engineering\n",
    "\n",
    "In Lab 6 we used the constant model. Now let's make a more complicated model that utilizes other features in our dataset. Let our prediction for tip be a combination of the following features:\n",
    "\n",
    "$$ \\text{Tip} = \\theta_1 \\cdot \\text{total}\\_\\text{bill} + \\theta_2 \\cdot \\text{sex} + \\theta_3 \\cdot \\text{smoker} + \\theta_4 \\cdot \\text{day} + \\theta_5 \\cdot \\text{time} + \\theta_6 \\cdot \\text{size} $$\n",
    "\n",
    "Notice that some of these features are not numbers! But our linear model will need to predict a numerical value. Let's start by converting some of these non-numerical values into numerical values. Below we split the tips and the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "split-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = data['tip']\n",
    "X = data.drop(columns='tip')\n",
    "type(X.head()['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1a: Feature Engineering\n",
    "\n",
    "First, let's convert our features to numerical values. A straightforward approach is to map some of these non-numerical features into numerical ones. \n",
    "\n",
    "For example, we can treat the day as a value from 1-7. However, one of the disadvantages in directly translating to a numeric value is that we unintentionally assign certain features disproportionate weight. Consider assigning Sunday to the numeric value of 7, and Monday to the numeric value of 1. In our linear model, Sunday will have 7 times the influence of Monday, which can lower the accuracy of our model.\n",
    "\n",
    "Instead, let's use one-hot encoding to better represent these features! \n",
    "\n",
    "As discussed in lecture, one-hot encoding will produce a binary vector indicating the non-numeric feature. \n",
    "\n",
    "In the `tips` dataset for example, we encode Sunday as the vector `[0 0 0 1]` because our dataset only contains bills from Thursday through Sunday. This assigns a more even weight across each category in non-numeric features. Complete the code below to one-hot encode our dataset, allowing us to see the transformed dataset named `one_hot_X`. This dataframe holds our \"featurized\" data, which is also often denoted by $\\phi$.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>size</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>smoker_Yes</th>\n",
       "      <th>smoker_No</th>\n",
       "      <th>day_Thur</th>\n",
       "      <th>day_Fri</th>\n",
       "      <th>day_Sat</th>\n",
       "      <th>day_Sun</th>\n",
       "      <th>time_Lunch</th>\n",
       "      <th>time_Dinner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill  size  sex_Male  sex_Female  smoker_Yes  smoker_No  day_Thur  \\\n",
       "0       16.99     2         0           1           0          1         0   \n",
       "1       10.34     3         1           0           0          1         0   \n",
       "2       21.01     3         1           0           0          1         0   \n",
       "3       23.68     2         1           0           0          1         0   \n",
       "4       24.59     4         0           1           0          1         0   \n",
       "\n",
       "   day_Fri  day_Sat  day_Sun  time_Lunch  time_Dinner  \n",
       "0        0        0        1           0            1  \n",
       "1        0        0        1           0            1  \n",
       "2        0        0        1           0            1  \n",
       "3        0        0        1           0            1  \n",
       "4        0        0        1           0            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode(data):\n",
    "    \"\"\"\n",
    "    Return the one-hot encoded dataframe of our input data.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    data: a dataframe that may include non-numerical features\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    A one-hot encoded dataframe that only contains numeric features\n",
    "    \n",
    "    \"\"\"\n",
    "    return pd.get_dummies(X)\n",
    "\n",
    "one_hot_X = one_hot_encode(X)\n",
    "one_hot_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q1a</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q1a passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1b: Defining the Model\n",
    "\n",
    "Now that all of our data is numeric, we can begin to define our model function. Notice that after one-hot encoding our data, we now have 12 features instead of 6. Therefore, our linear model now looks like:\n",
    "\n",
    "$$ \\text{Tip} = \\theta_1 \\cdot \\text{size} + \\theta_2 \\cdot \\text{total}\\_\\text{bill} + \\theta_3 \\cdot \\text{day}\\_\\text{Thur} + \\theta_4 \\cdot \\text{day}\\_\\text{Fri} + ... + \\theta_{11} \\cdot \\text{time}\\_\\text{Lunch} + \\theta_{12} \\cdot \\text{time}\\_\\text{Dinner} $$\n",
    "\n",
    "We can represent the linear combination above as a matrix-vector product. Implement the `linear_model` function to evaluate this product.\n",
    "\n",
    "**Hint**: You can use [np.dot](https://numpy.org/doc/stable/reference/generated/numpy.dot.html), [pd.DataFrame.dot](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dot.html), or the `@` operator to multiply matrices/vectors. However, while the `@` operator can be used to multiply `numpy` arrays, it generally will not work between two `pandas` objects, so keep that in mind when computing matrix-vector products!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def linear_model(thetas, X):\n",
    "    \"\"\"\n",
    "    Return the linear combination of thetas and features as defined above.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    thetas: a 1D vector representing the parameters of our model ([theta1, theta2, ...])\n",
    "    X: a 2D dataframe of numeric features (may also be a 2D numpy array)\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    A 1D vector representing the linear combination of thetas and features as defined above.\n",
    "    \"\"\"\n",
    "    if(type(X) == pd.core.frame.DataFrame): X = X.to_numpy()\n",
    "    if(type(thetas) == pd.core.series.Series): thetas = thetas.to_numpy()\n",
    "    return X @ thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q1b</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q1b passed!"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 2: Fitting the Model using Numeric Methods\n",
    "\n",
    "Recall in Lab 6 we defined multiple loss functions and found THE optimal theta using the `scipy.minimize` function. Adapt the loss functions and optimization code from Lab 6 (provided below) to work with our new linear model.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09448685, 0.1759931 , 0.04125392, 0.07369406, 0.01426988,\n",
       "       0.10067805, 0.44377398, 0.60603582, 0.4845789 , 0.58055644,\n",
       "       0.09154036, 0.02340759])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def l1(y, y_hat):\n",
    "    return np.abs(y - y_hat)\n",
    "\n",
    "def l2(y, y_hat):\n",
    "    return (y - y_hat)**2\n",
    "\n",
    "def minimize_average_loss(loss_function, model, X, y):\n",
    "    \"\"\"\n",
    "    Minimize the average loss calculated from using different theta vectors, and \n",
    "    estimate the optimal theta for the model.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    loss_function: either the squared or absolute loss functions defined above\n",
    "    model: the model (as defined in Question 1b)\n",
    "    X: a 2D dataframe (or numpy array) of numeric features (one-hot encoded)\n",
    "    y: a 1D vector of tip amounts\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    The estimate for the optimal theta vector that minimizes our loss\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Notes on the following function call which you need to finish:\n",
    "    # \n",
    "    # 0. The first '...' should be replaced with the average loss evaluated on \n",
    "    #       the data X, y using the model and appropriate loss function.\n",
    "    # 1. x0 are the initial values for THETA.  Yes, this is confusing\n",
    "    #       but optimization people like x to be the thing they are \n",
    "    #       optimizing. Replace the second '...' with an initial value for theta,\n",
    "    #       and remember that theta is now a vector. DO NOT hard-code the length of x0;\n",
    "    #       it should depend on the number of features in X.\n",
    "    # 2. Your answer will be very similar to your answer to question 2 from lab 7.\n",
    "    \n",
    "    return minimize(lambda theta: np.mean(loss_function(y, model(theta, X))),\\\n",
    "                           x0=np.ones(X.shape[1]))['x']\n",
    "    # Notice above that we extract the 'x' entry in the dictionary returned by `minimize`. \n",
    "    # This entry corresponds to the optimal theta estimated by the function.\n",
    "\n",
    "minimize_average_loss(l2, linear_model, one_hot_X, tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q2</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q2 passed!"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 3: Fitting the Model using Analytic Methods\n",
    "\n",
    "Let's also fit our model analytically for the l2 loss function. Recall from lecture that with a linear model, we are solving the following optimization problem for least squares:\n",
    "\n",
    "$$\\min_{\\theta} ||\\Bbb{X}\\theta - \\Bbb{y}||^2$$\n",
    "\n",
    "We showed in lecture that the optimal $\\hat{\\theta}$ is given by the equation:\n",
    "$$\\hat{\\theta} = (\\Bbb{X}^T \\Bbb{X})^{-1} \\Bbb{X}^T \\Bbb{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3a: Analytic Solution Using Explicit Inverses\n",
    "\n",
    "For this problem, implement the analytic solution above using `np.linalg.inv` to compute the inverse of $X^TX$.\n",
    "\n",
    "Reminder: To compute the transpose of a matrix, you can use `X.T` or `X.transpose()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_analytical_sol(X, y):\n",
    "    \"\"\"\n",
    "    Computes the analytical solution to our least squares problem\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    X: a 2D dataframe (or numpy array) of numeric features (one-hot encoded)\n",
    "    y: a 1D vector of tip amounts\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    The estimate for theta computed using the equation mentioned above\n",
    "    \"\"\"\n",
    "    return np.linalg.inv(X.T @ X) @ X.T @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to find the analytical solution for the `tips` dataset. Depending on the machine that you run your code on, you should either see an error or end up with thetas that are nonsensical (magnitudes greater than 10^15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2.809678e+00\n",
       "1    -1.133097e+00\n",
       "2     3.756072e+16\n",
       "3     3.756072e+16\n",
       "4    -3.756072e+16\n",
       "5    -3.756072e+16\n",
       "6    -2.037422e+01\n",
       "7    -1.450141e+01\n",
       "8    -7.027344e+00\n",
       "9    -1.973414e+01\n",
       "10    9.595937e+00\n",
       "11    1.819977e+01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytical_thetas = get_analytical_sol(one_hot_X, tips)\n",
    "analytical_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below, explain why we got the error above when trying to calculate the analytical solution for our one-hot encoded `tips` dataset.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X^TX$ is not invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3b: Fixing our One-Hot Encoding\n",
    "\n",
    "Now, let's fix our one-hot encoding approach so we don't get the error we did earlier. Complete the code below to one-hot-encode our dataset such that `one_hot_X_revised` has no redundant features.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our analytical loss is:  1.0488354462975855\n",
      "Our numerical loss is:  1.0488354462997158\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode_revised(data):\n",
    "    \"\"\"\n",
    "    Return the one-hot encoded dataframe of our input data, removing redundancies.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    data: a dataframe that may include non-numerical features\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    A one-hot encoded dataframe that only contains numeric features without any redundancies.\n",
    "    \n",
    "    \"\"\"\n",
    "    origin_one_hot = pd.get_dummies(X)\n",
    "    return origin_one_hot.drop(['sex_Female', 'smoker_No', 'day_Sun', 'time_Dinner'], axis=1)\n",
    "one_hot_X_revised = one_hot_encode_revised(X)\n",
    "revised_analytical_thetas = get_analytical_sol(one_hot_X_revised, tips)\n",
    "print(\"Our analytical loss is: \", l2(linear_model(revised_analytical_thetas, one_hot_X_revised), tips).mean())\n",
    "print(\"Our numerical loss is: \", l2(linear_model(minimize_average_loss(l2, linear_model, one_hot_X_revised, tips), one_hot_X_revised), tips).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q3b</strong> passed!</p>\n",
       "    "
      ],
      "text/plain": [
       "q3b passed!"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3c: Analyzing our new One-Hot Encoding\n",
    "\n",
    "Why did removing redundancies in our one-hot encoding fix the problem we had in 3a?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3c\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if all of the one-hot encode is included, then $rank(X)<n$, $X^TX$ won't be invertible (collinearity).\n",
    "It is so-called \"Dummy variable trap\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Note: An alternate approach is to use `np.linalg.solve` instead of `np.linalg.inv`. For the example above, even with the redundant features, `np.linalg.solve` will work well. Though in general, it's best to drop redundant features anyway.\n",
    "\n",
    "In case you want to learn more, here is a relevant Stack Overflow post: https://stackoverflow.com/questions/31256252/why-does-numpy-linalg-solve-offer-more-precise-matrix-inversions-than-numpy-li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <p><strong>q1a</strong> passed!</p>\n",
       "    \n",
       "\n",
       "\n",
       "    <p><strong>q1b</strong> passed!</p>\n",
       "    \n",
       "\n",
       "\n",
       "    <p><strong>q2</strong> passed!</p>\n",
       "    \n",
       "\n",
       "\n",
       "    <p><strong>q3b</strong> passed!</p>\n",
       "    \n",
       "\n"
      ],
      "text/plain": [
       "q1a passed!\n",
       "\n",
       "q1b passed!\n",
       "\n",
       "q2 passed!\n",
       "\n",
       "q3b passed!\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <p>Your submission has been exported. Click <a href=\"lab08.zip\" target=\"_blank\">here</a>\n",
       "                to download the zip file.</p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(\"lab08.ipynb\", pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
